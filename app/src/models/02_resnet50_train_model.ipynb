{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Imports and Setup\n",
    "Sets up the environment and defines the path to custom modules."
   ],
   "id": "c5b8f5c7dd424d2d"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import sagemaker\n",
    "import boto3\n",
    "from sagemaker import image_uris, estimator, inputs\n",
    "\n",
    "# --- 1. Session Setup ---\n",
    "sess = sagemaker.Session()\n",
    "region = boto3.Session().region_name\n",
    "role = sagemaker.get_execution_role()\n",
    "bucket = sess.default_bucket()\n",
    "\n",
    "# IMPORTANT: This must match the prefix used in 01-preprocessing.ipynb\n",
    "prefix = \"cbis-ddsm-classification\"\n",
    "\n",
    "print(f\"Region: {region}\")\n",
    "print(f\"Bucket: {bucket}\")\n",
    "print(f\"Using Data Prefix: {prefix}\")\n",
    "\n",
    "# Path to the folder containing all images\n",
    "s3_images = f\"s3://{bucket}/{prefix}/images\"\n",
    "\n",
    "# Paths to the .lst files (Manifests)\n",
    "s3_train_lst = f\"s3://{bucket}/{prefix}/metadata/train.lst\"\n",
    "s3_val_lst = f\"s3://{bucket}/{prefix}/metadata/validation.lst\"\n",
    "\n",
    "print(f\"Training Data: {s3_images}\")\n",
    "print(f\"Manifest: {s3_train_lst}\")"
   ],
   "id": "604de6102e5311ba"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Model Setup: Retrieve Image & Define Estimator\n",
    "We load the SageMaker Built-in Image Classification algorithm container."
   ],
   "id": "d1ed11542c2186fd"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Retrieve the Docker image for the Built-in Image Classification algorithm\n",
    "training_image = image_uris.retrieve(\n",
    "    region=region,\n",
    "    framework='image-classification',\n",
    "    image_scope='training'\n",
    ")\n",
    "\n",
    "# Configure the training job (Compute resources)\n",
    "estimator_config = estimator.Estimator(\n",
    "    image_uri=training_image,\n",
    "    role=role,\n",
    "    instance_count=1,\n",
    "    instance_type='ml.g4dn.xlarge', # ~$0.736/hour\n",
    "    volume_size=50,                # 50 GB of storage on the training instance\n",
    "    max_run=7200 ,                  # Timeout (2 hours)\n",
    "    output_path=f\"s3://{bucket}/{prefix}/output\",\n",
    "    sagemaker_session=sess\n",
    ")"
   ],
   "id": "1e32344a933fb21e"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Hyperparameters (ResNet-50 Config)\n",
    "This is where we tell SageMaker to use ResNet50 with Transfer Learning."
   ],
   "id": "cf601514a8a95d7"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "s3 = boto3.client('s3')\n",
    "s3.download_file(bucket, f\"{prefix}/metadata/train.lst\", \"train_temp.lst\")\n",
    "\n",
    "with open(\"train_temp.lst\", \"r\") as f:\n",
    "    num_training_samples = sum(1 for _ in f)\n",
    "\n",
    "print(f\"Number of samples: {num_training_samples}\")\n",
    "\n",
    "estimator_config.set_hyperparameters(\n",
    "    num_layers=50,\n",
    "    use_pretrained_model=1,\n",
    "    image_shape=\"3,224,224\",\n",
    "    num_classes=2,\n",
    "    num_training_samples=num_training_samples,\n",
    "    mini_batch_size=32,\n",
    "    epochs=20,\n",
    "    learning_rate=0.001,\n",
    "    optimizer='adam',\n",
    "\n",
    "    # Early Stopping to prevent overfitting\n",
    "    early_stopping=True,\n",
    "    early_stopping_patience=3,\n",
    "    early_stopping_min_epochs=5,\n",
    "    early_stopping_tolerance=0.0\n",
    ")"
   ],
   "id": "fa93025acf831d35"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Training Execution\n",
    "Map the inputs and start the job."
   ],
   "id": "90caec276f4f11fa"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Define Input Configuration\n",
    "\n",
    "# The algorithm needs to know that 'train' contains images, but uses 'train_lst' as the map.\n",
    "images_data = inputs.TrainingInput(\n",
    "    s3_data=s3_images,\n",
    "    content_type='application/x-image',\n",
    "    s3_data_type='S3Prefix',\n",
    "    input_mode='File'\n",
    ")\n",
    "\n",
    "# Mapping the channels\n",
    "data_channels = {\n",
    "    'train': images_data,\n",
    "    'validation': images_data,\n",
    "    'train_lst': inputs.TrainingInput(s3_train_lst, content_type='application/x-image'),\n",
    "    'validation_lst': inputs.TrainingInput(s3_val_lst, content_type='application/x-image')\n",
    "}\n",
    "\n",
    "# START!\n",
    "print(\"Starting training job... this will take a few minutes.\")\n",
    "estimator_config.fit(inputs=data_channels)"
   ],
   "id": "f16b7030387caaea"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Training Execution with Optimization Hyperparameters ( Random Search )\n",
    "Map the inputs and start the job."
   ],
   "id": "a3ca70933a649fd7"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "from sagemaker.tuner import HyperparameterTuner, ContinuousParameter, IntegerParameter, CategoricalParameter\n",
    "\n",
    "# Define Search Ranges (Search Space)\n",
    "# Here we define the ranges where Random Search will \"sample\" values\n",
    "hyperparameter_ranges = {\n",
    "    'learning_rate': ContinuousParameter(0.0001, 0.1), # Tries values between 0.0001 and 0.1\n",
    "    'mini_batch_size': CategoricalParameter([16, 32, 64]), # Chooses one of these sizes\n",
    "    'optimizer': CategoricalParameter(['sgd', 'adam', 'rmsprop']), # Tests different optimizers\n",
    "    'momentum': ContinuousParameter(0.0, 0.9) # Only for SGD, but the tuner tests it\n",
    "}\n",
    "\n",
    "# Configure Success Metric\n",
    "# We tell SageMaker: \"The best model is the one with the highest validation accuracy\"\n",
    "objective_metric_name = 'validation:accuracy'\n",
    "objective_type = 'Maximize'\n",
    "\n",
    "# --- 7. Configure the Tuner (The Conductor) ---\n",
    "tuner = HyperparameterTuner(\n",
    "    estimator=estimator_config,              # The model we defined earlier (ResNet50)\n",
    "    objective_metric_name=objective_metric_name,\n",
    "    hyperparameter_ranges=hyperparameter_ranges,\n",
    "    objective_type=objective_type,\n",
    "\n",
    "    # Random Search Configurations\n",
    "    strategy='Random',                   # <--- HERE we define it as Random Search\n",
    "    max_jobs=5,                         # Total training jobs to run (Cost)\n",
    "    max_parallel_jobs=2,                 # How many jobs run concurrently (Watch out for account limits)\n",
    "    early_stopping_type='Auto'           # The Tuner itself stops bad jobs early\n",
    ")\n",
    "\n",
    "# START OPTIMIZATION!\n",
    "print(\"Starting Hyperparameter Optimization jobs (Random Search)...\")\n",
    "\n",
    "# We pass the data channels (same as normal fit)\n",
    "tuner.fit(inputs=data_channels)\n",
    "\n",
    "print(\"Wait... you can monitor progress in the SageMaker console.\")"
   ],
   "id": "fad33cac2f197078"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
